{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c1ecc6d8",
      "metadata": {
        "id": "c1ecc6d8"
      },
      "source": [
        "## Initial Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "98d4c808",
      "metadata": {
        "id": "98d4c808"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import math\n",
        "import glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM,TimeDistributed\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.layers import Add, Lambda, Multiply, Activation, Dense, Dropout, Conv2D, ConvLSTM2D, Conv2DTranspose, BatchNormalization, UpSampling2D,MaxPooling2D, concatenate, Flatten, Reshape\n",
        "from tensorflow.keras.metrics import RootMeanSquaredError\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.models import load_model, Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Synthetic Data Generation\n",
        "This step can be skipped if data is being loaded directly from npy file\n"
      ],
      "metadata": {
        "id": "zvasUCz7plMu"
      },
      "id": "zvasUCz7plMu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b1de778",
      "metadata": {
        "id": "9b1de778"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy.ndimage\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Parameters\n",
        "Lx = 10.0      # Length of the domain in the x direction\n",
        "Ly = 10.0      # Length of the domain in the y direction\n",
        "Nx = 28        # Number of spatial points in the x direction\n",
        "Ny = 28        # Number of spatial points in the y direction\n",
        "Nt = 5000      # Number of time steps\n",
        "D_a = 0.01     # Diffusion coefficient for variable a\n",
        "D_b = 0.01     # Diffusion coefficient for variable b\n",
        "D_c = 0.01     # Diffusion coefficient for variable c (combination of a and b)\n",
        "alpha = 0.1    # Influence of variable_a on variable_b\n",
        "beta = 0.2     # Coefficient for variable_a in variable_c\n",
        "gamma = 0.3    # Coefficient for variable_b in variable_c\n",
        "neighborhood_size = 3  # Size of the neighborhood for convolution\n",
        "lag_a = 1      # Lag for variable_a\n",
        "lag_b = 1      # Lag for variable_b\n",
        "update_factor_b = 0.6  # Update factor for variable_b\n",
        "\n",
        "# Spatial and temporal discretization\n",
        "x = np.linspace(0, Lx, Nx)\n",
        "y = np.linspace(0, Ly, Ny)\n",
        "X, Y = np.meshgrid(x, y)\n",
        "dx = x[1] - x[0]\n",
        "dy = y[1] - y[0]\n",
        "\n",
        "# Time discretization\n",
        "dt = 0.01      # Time step\n",
        "t = np.linspace(0, Nt * dt, Nt)\n",
        "\n",
        "# Initialize variables\n",
        "variable_a = np.zeros((Nt, Nx, Ny))\n",
        "variable_b = np.zeros((Nt, Nx, Ny))\n",
        "variable_b_cf = np.zeros((Nt, Nx, Ny))\n",
        "variable_c = np.zeros((Nt, Nx, Ny))\n",
        "variable_c_cf = np.zeros((Nt, Nx, Ny))\n",
        "\n",
        "# Initial conditions\n",
        "variable_a[0, :, :] = np.exp(-((X - Lx/2)**2 + (Y - Ly/2)**2) / 4)\n",
        "variable_b[0, :, :] = np.sin(np.pi * X / Lx) + alpha * variable_a[0, :, :]\n",
        "#variable_b_cf[0, :, :] = np.cos(np.pi * X / Lx) + alpha * variable_a[0, :, :]\n",
        "variable_c[0, :, :] = beta * variable_a[0, :, :] + gamma * variable_b[0, :, :]\n",
        "variable_c_cf[0, :, :] = beta * variable_a[0, :, :] + gamma * variable_b[0, :, :]\n",
        "\n",
        "# Time-stepping loop\n",
        "for n in range(1, Nt):\n",
        "    # Diffusion Equation for variable_a with time lag\n",
        "    laplacian_a = (np.roll(variable_a[n-1, :, :], 1, axis=1) - 2 * variable_a[n-1, :, :] + np.roll(variable_a[n-1, :, :], -1, axis=1)) / dx**2 + \\\n",
        "                   (np.roll(variable_a[n-1, :, :], 1, axis=0) - 2 * variable_a[n-1, :, :] + np.roll(variable_a[n-1, :, :], -1, axis=0)) / dy**2\n",
        "    diffusion_term_a = D_a * laplacian_a\n",
        "    variable_a[n, :, :] = variable_a[n-1, :, :] + dt * diffusion_term_a\n",
        "\n",
        "    # Diffusion Equation for variable_b with time lag and dependence on lagged variable_a\n",
        "    laplacian_b = (np.roll(variable_b[n-1, :, :], 1, axis=1) - 2 * variable_b[n-1, :, :] + np.roll(variable_b[n-1, :, :], -1, axis=1)) / dx**2 + \\\n",
        "                   (np.roll(variable_b[n-1, :, :], 1, axis=0) - 2 * variable_b[n-1, :, :] + np.roll(variable_b[n-1, :, :], -1, axis=0)) / dy**2\n",
        "    diffusion_term_b = D_b * laplacian_b\n",
        "    variable_b[n, :, :] = (variable_b[n-1, :, :] + dt * (diffusion_term_b + alpha * np.roll(diffusion_term_a, lag_a, axis=(0, 1))))\n",
        "    variable_b_cf[n, :, :] = (variable_b[n-1, :, :] + dt * (diffusion_term_b + alpha * np.roll(diffusion_term_a, lag_a, axis=(0, 1))))\n",
        "\n",
        "    variable_b_cf[n,10:15,10:15] = update_factor_b * variable_b_cf[n,10:15,10:15]\n",
        "\n",
        "    # Convolution to compute the mean of per-pixel neighborhood of variable_b (excluding the pixel itself)\n",
        "    kernel_size = 3\n",
        "    neighborhood_sum = scipy.ndimage.convolve(variable_b[n, :, :], np.ones((kernel_size, kernel_size)), mode='constant', cval=0)\n",
        "    neighborhood_mean = (neighborhood_sum - variable_b[n, :, :]) / (kernel_size**2 - 1)\n",
        "\n",
        "    # Diffusion Equation for variable_c with time lag and dependence on lagged variable_a and lagged variable_b\n",
        "    laplacian_c = (np.roll(variable_c[n-1, :, :], 1, axis=1) - 2 * variable_c[n-1, :, :] + np.roll(variable_c[n-1, :, :], -1, axis=1)) / dx**2 + \\\n",
        "                   (np.roll(variable_c[n-1, :, :], 1, axis=0) - 2 * variable_c[n-1, :, :] + np.roll(variable_c[n-1, :, :], -1, axis=0)) / dy**2\n",
        "    diffusion_term_c = D_c * laplacian_c\n",
        "    variable_c[n, :, :] = variable_c[n-1, :, :] + dt * diffusion_term_c + beta * dt * np.roll(diffusion_term_a, lag_a, axis=(0, 1)) + gamma * dt * (np.roll(variable_b[n, :, :], lag_b, axis=(0, 1)))# + neighborhood_mean)\n",
        "\n",
        "#variable_b_cf = np.copy(variable_b)\n",
        "#variable_b_cf[:,10:20,10:20] = variable_b_cf[:,10:20,10:20] * 1.5\n",
        "\n",
        "for n in range(1, Nt):\n",
        "  # Diffusion Equation for variable_c with time lag and dependence on lagged variable_a and lagged variable_b\n",
        "    laplacian_cf = (np.roll(variable_c_cf[n-1, :, :], 1, axis=1) - 2 * variable_c_cf[n-1, :, :] + np.roll(variable_c_cf[n-1, :, :], -1, axis=1)) / dx**2 + \\\n",
        "                   (np.roll(variable_c_cf[n-1, :, :], 1, axis=0) - 2 * variable_c_cf[n-1, :, :] + np.roll(variable_c_cf[n-1, :, :], -1, axis=0)) / dy**2\n",
        "    diffusion_term_cf = D_c * laplacian_cf\n",
        "    variable_c_cf[n, :, :] = variable_c_cf[n-1, :, :] + dt * diffusion_term_cf + beta * dt * np.roll(diffusion_term_a, lag_a, axis=(0, 1)) + gamma * dt * (np.roll(variable_b_cf[n, :, :], lag_b, axis=(0, 1)))# + neighborhood_mean)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9bc67c5e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bc67c5e",
        "outputId": "29cb3dbb-071b-4d65-8410-dea437de160c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5000, 28, 28, 4)\n"
          ]
        }
      ],
      "source": [
        "a = variable_a.reshape(5000, 28, 28, 1)\n",
        "b = variable_b.reshape(5000, 28, 28, 1)\n",
        "c = variable_c.reshape(5000, 28, 28, 1)\n",
        "c_cf = variable_c_cf.reshape(5000, 28, 28, 1)\n",
        "data = np.concatenate([a, b, c, c_cf], 3)\n",
        "print(data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a73ecb20",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a73ecb20",
        "outputId": "f5f49f50-2c24-40c2-fcc8-64549fdfec09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5000, 28, 28)\n",
            "(5000, 28, 28, 3)\n",
            "(5000, 28, 28, 2)\n",
            "(5000, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "data = data[:,:,:,:]\n",
        "cov = data[:,:,:,:-2]\n",
        "cf_data = data[:,:,:,-1]\n",
        "target = data[:,:,:,-2]\n",
        "data = data[:,:,:,:-1]\n",
        "\n",
        "print(cf_data.shape)\n",
        "print(data.shape)\n",
        "print(cov.shape)\n",
        "print(target.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6d732af",
      "metadata": {
        "id": "d6d732af"
      },
      "outputs": [],
      "source": [
        "#Adding a lag to target\n",
        "lag = 1\n",
        "\n",
        "data = data[lag:-lag,:,:,:]\n",
        "target = target[lag+1:,:,:]\n",
        "cf_data = cf_data[lag+1:,:,:]\n",
        "cov = cov[:-(lag+1),:,:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "527da033",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "527da033",
        "outputId": "961a5eab-6f3d-4959-eaf7-7176b2593a81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4998, 28, 28, 3) (4998, 28, 28, 2)\n",
            "(4998, 28, 28) (4998, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "print(data.shape, cov.shape)\n",
        "print(target.shape, cf_data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd77cca6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd77cca6",
        "outputId": "252b030c-5506-47c5-9c6c-bd59c669faaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(4998, 28, 28, 1)\n",
            "(4998, 28, 28, 3)\n",
            "(4998, 28, 28, 2)\n",
            "(4998, 28, 28, 3)\n"
          ]
        }
      ],
      "source": [
        "## Shifting treatment to last column\n",
        "\n",
        "tr = data[:,:,:,-2].copy()\n",
        "tr = tr.reshape(data.shape[0], data.shape[1], data.shape[2],1)\n",
        "print(tr.shape)\n",
        "print(data.shape)\n",
        "data = np.delete(data, -2, 3)\n",
        "print(data.shape)\n",
        "data = np.concatenate([data, tr], 3)\n",
        "print(data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4a2b1e1",
      "metadata": {
        "id": "f4a2b1e1"
      },
      "outputs": [],
      "source": [
        "LEN_DATA = len(data) #total number of pixels\n",
        "NUM_TRAIN = LEN_DATA\n",
        "NUM_TEST = int(LEN_DATA * 1)\n",
        "\n",
        "print('LEN_DATA:',LEN_DATA)\n",
        "print('NUM_TRAIN:',NUM_TRAIN)\n",
        "\n",
        "\n",
        "x_train = data[:,:,:,:]\n",
        "x_test = data[:,:,:,:]\n",
        "\n",
        "#Create input2 of treatment and covariate history\n",
        "x_train2 = cov[:,:,:,:]\n",
        "x_test2 = cov[:,:,:,:]\n",
        "\n",
        "\n",
        "#split features and labels\n",
        "y_train=target[:,:,:] #target is last column\n",
        "y_test=target[:,:,:] #target is last column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20be84be",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20be84be",
        "outputId": "d762ec3b-5ce1-45cb-d90c-151cd509da74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train.shape: (4998, 28, 28, 3)\n",
            "y_train.shape: (4998, 28, 28)\n",
            "x_train2.shape: (4998, 28, 28, 2)\n",
            "x_test.shape: (4998, 28, 28, 3)\n",
            "x_test2.shape: (4998, 28, 28, 2)\n",
            "y_test.shape: (4998, 28, 28)\n"
          ]
        }
      ],
      "source": [
        "print('x_train.shape:',x_train.shape)\n",
        "print('y_train.shape:',y_train.shape)\n",
        "print('x_train2.shape:',x_train2.shape)\n",
        "\n",
        "print('x_test.shape:',x_test.shape)\n",
        "print('x_test2.shape:',x_test2.shape)\n",
        "print('y_test.shape:',y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37c462fe",
      "metadata": {
        "id": "37c462fe"
      },
      "outputs": [],
      "source": [
        "#Replacing all nans with Zeros\n",
        "x_train = np.nan_to_num(x_train)\n",
        "x_train2 = np.nan_to_num(x_train2)\n",
        "y_train = np.nan_to_num(y_train)\n",
        "x_test = np.nan_to_num(x_test)\n",
        "x_test2 = np.nan_to_num(x_test2)\n",
        "y_test = np.nan_to_num(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ee50088d",
      "metadata": {
        "id": "ee50088d"
      },
      "outputs": [],
      "source": [
        "#Applying treatment to selective region\n",
        "\n",
        "x_treated = np.copy(x_test)\n",
        "x_treated[:,10:15,10:15,-1] = x_treated[:,10:15,10:15,-1]*(0.6)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "257faa53",
      "metadata": {
        "id": "257faa53"
      },
      "source": [
        "### Reshaping Input and Target Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "570c1b5d",
      "metadata": {
        "id": "570c1b5d"
      },
      "outputs": [],
      "source": [
        "# convert an array of values into a dataset matrix\n",
        "def reshape_features(dataset, samples, timestep, lat, lon, features):\n",
        "    print(dataset.shape)\n",
        "    X = dataset.reshape(samples, timestep, lat, lon, features)\n",
        "    return X\n",
        "\n",
        "# convert an array of values into a dataset matrix\n",
        "def reshape_outcome(dataset, months, lat, lon):\n",
        "    print(dataset.shape)\n",
        "    X = dataset.reshape(months, lat, lon, 1)\n",
        "    return X"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2a1f5f1",
      "metadata": {
        "id": "b2a1f5f1"
      },
      "source": [
        "### Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "732da376",
      "metadata": {
        "id": "732da376"
      },
      "outputs": [],
      "source": [
        "# normalize the features\n",
        "\n",
        "scaler_f = StandardScaler()\n",
        "x_train = scaler_f.fit_transform(x_train.reshape(-1,x_train.shape[-1])) #reshaping to 2d for standard scaling\n",
        "x_test = scaler_f.transform(x_test.reshape(-1,x_test.shape[-1])) #reshaping to 2d for standard scaling\n",
        "x_treated = scaler_f.transform(x_treated.reshape(-1,x_treated.shape[-1])) #reshaping to 2d for standard scaling\n",
        "\n",
        "scaler_h = StandardScaler()\n",
        "x_train2 = scaler_h.fit_transform(x_train2.reshape(-1,x_train2.shape[-1])) #reshaping to 2d for standard scaling\n",
        "x_test2 = scaler_h.transform(x_test2.reshape(-1,x_test2.shape[-1])) #reshaping to 2d for standard scaling\n",
        "#x_treated2 = scaler_h.transform(x_treated2.reshape(-1,x_treated2.shape[-1])) #reshaping to 2d for standard scaling\n",
        "\n",
        "\n",
        "scaler_l = StandardScaler()\n",
        "y_train = scaler_l.fit_transform(y_train.reshape(-1,1)) #reshaping to 2d for standard scaling\n",
        "y_test = scaler_l.transform(y_test.reshape(-1,1)) #reshaping to 2d for standard scaling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b2f8a6d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b2f8a6d",
        "outputId": "8c5b3d39-fc1a-4cd1-f5d6-bfe4a7c1d42e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train.shape: (3918432, 3)\n",
            "x_train2.shape: (3918432, 2)\n",
            "y_train.shape: (3918432, 1)\n",
            "x_test.shape: (3918432, 3)\n",
            "y_test.shape: (3918432, 1)\n"
          ]
        }
      ],
      "source": [
        "print('x_train.shape:',x_train.shape)\n",
        "print('x_train2.shape:',x_train2.shape)\n",
        "print('y_train.shape:',y_train.shape)\n",
        "\n",
        "print('x_test.shape:',x_test.shape)\n",
        "print('y_test.shape:',y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "19c1e434",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "19c1e434",
        "outputId": "46a09f37-13b8-4325-b693-b3911785d35e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3918432, 3)\n",
            "(3918432, 3)\n",
            "(3918432, 3)\n",
            "(3918432, 2)\n",
            "(3918432, 2)\n",
            "(3918432, 1)\n",
            "(3918432, 1)\n"
          ]
        }
      ],
      "source": [
        "#Reshaping data to 3D for modeling\n",
        "lat = 28\n",
        "lon = 28\n",
        "features = 3\n",
        "features2 = 2\n",
        "timestep = 1\n",
        "\n",
        "x_train = reshape_features(x_train, NUM_TRAIN, timestep, lat, lon, features) # reshaping to 3d for model\n",
        "x_test = reshape_features(x_test, NUM_TRAIN, timestep, lat, lon, features) # reshaping to 3d for model\n",
        "x_treated = reshape_features(x_treated, NUM_TRAIN, timestep, lat, lon, features) #reshaping to 2d for standard scaling\n",
        "\n",
        "x_train2 = reshape_features(x_train2, NUM_TRAIN, timestep, lat, lon, features2) # reshaping to 3d for model\n",
        "x_test2 = reshape_features(x_test2, NUM_TRAIN, timestep, lat, lon, features2) # reshaping to 3d for model\n",
        "\n",
        "y_train = reshape_outcome(y_train, NUM_TRAIN, lat, lon) # reshaping to 3d for model\n",
        "y_test = reshape_outcome(y_test, NUM_TRAIN, lat, lon) # reshaping to 3d for model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4d84299",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4d84299",
        "outputId": "8c576335-da7e-4610-cb81-922da14c588b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train.shape: (4998, 1, 28, 28, 3)\n",
            "x_train2.shape: (4998, 1, 28, 28, 2)\n",
            "y_train.shape: (4998, 28, 28, 1)\n",
            "x_test.shape: (4998, 1, 28, 28, 3)\n",
            "x_test2.shape: (4998, 1, 28, 28, 2)\n",
            "x_treated.shape: (4998, 1, 28, 28, 3)\n",
            "y_test.shape: (4998, 28, 28, 1)\n"
          ]
        }
      ],
      "source": [
        "print('x_train.shape:',x_train.shape)\n",
        "print('x_train2.shape:',x_train2.shape)\n",
        "print('y_train.shape:',y_train.shape)\n",
        "\n",
        "print('x_test.shape:',x_test.shape)\n",
        "print('x_test2.shape:',x_test2.shape)\n",
        "print('x_treated.shape:',x_treated.shape)\n",
        "print('y_test.shape:',y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03f602c3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03f602c3",
        "outputId": "3aaf2a53-4475-4689-c7d9-7a10815c21c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 28, 28, 2) (1, 28, 28, 3)\n"
          ]
        }
      ],
      "source": [
        "lat = 28\n",
        "lon = 28\n",
        "features2 = 3 #actual features\n",
        "features = 2 #history\n",
        "timestep = 1\n",
        "\n",
        "input1_shape = (timestep, lat, lon, features)\n",
        "input2_shape = (timestep, lat, lon, features2)\n",
        "\n",
        "filter_size=3\n",
        "use_temp_scaling=False\n",
        "n_output_classes=1\n",
        "metrics = RootMeanSquaredError()\n",
        "print(input1_shape, input2_shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Input, UpSampling2D, concatenate, Activation, Multiply, Add, Lambda, GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, Dense, Permute\n",
        "import tensorflow as tf\n",
        "\n",
        "def spatial_attention_module(input_tensor):\n",
        "    \"\"\"Generate a spatial attention map and multiply it by the input tensor.\"\"\"\n",
        "    # Average pooling and max pooling\n",
        "    avg_pool = Lambda(lambda x: tf.reduce_mean(x, axis=-1, keepdims=True))(input_tensor)\n",
        "    max_pool = Lambda(lambda x: tf.reduce_max(x, axis=-1, keepdims=True))(input_tensor)\n",
        "    concat = concatenate([avg_pool, max_pool], axis=-1)\n",
        "\n",
        "    # Convolution layer to generate the attention map\n",
        "    attention = Conv2D(filters=1, kernel_size=(7, 7), padding='same', activation='sigmoid')(concat)\n",
        "\n",
        "    # Multiply the input tensor by the attention map\n",
        "    output_tensor = Multiply()([input_tensor, attention])\n",
        "    return output_tensor\n"
      ],
      "metadata": {
        "id": "SL_LxUAeOMfz"
      },
      "id": "SL_LxUAeOMfz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9cf249be",
      "metadata": {
        "id": "9cf249be"
      },
      "outputs": [],
      "source": [
        "    input1 = Input(shape=input1_shape)\n",
        "    input2 = Input(shape=input2_shape)\n",
        "\n",
        "    #LFM Block-----start---------\n",
        "    convlstm1 = ConvLSTM2D(8, (5,5), padding=\"same\", return_sequences=False, data_format=\"channels_last\")(input1)\n",
        "    conv = Conv2D(16, filter_size, activation='relu', padding='same', kernel_initializer='he_normal')(convlstm1)\n",
        "    drop = Dropout(0.2)(conv)\n",
        "    conv = Conv2D(16, (1,1), activation='relu', padding='same', kernel_initializer='he_normal')(drop)\n",
        "    bn = BatchNormalization(axis=-1)(conv)\n",
        "    print('K.int_shape(drop)',K.int_shape(drop))\n",
        "    out = Flatten()(bn)\n",
        "    out = Dense (64, activation = \"relu\")(out)\n",
        "    out = Dense(28*28, activation = \"linear\")(out)\n",
        "    out = Reshape((28, 28, 1), input_shape=(28*28,), name=\"lfm_output\")(out)\n",
        "\n",
        "    #LFM Block-----end---------\n",
        "\n",
        "    #Merge LFM Block with input-----------\n",
        "    convlstm2 = ConvLSTM2D(8, (5,5), padding=\"same\", return_sequences=False, data_format=\"channels_last\")(input2)\n",
        "    print('K.int_shape(convlstm2)',K.int_shape(convlstm2))\n",
        "    merge0 = concatenate([conv,convlstm2], axis=3)\n",
        "    print('K.int_shape(merge0)',K.int_shape(merge0))\n",
        "\n",
        "    #UNet-----start-----------\n",
        "    conv1 = Conv2D(64, filter_size, activation='relu', padding='same', kernel_initializer='he_normal')(merge0)\n",
        "    conv1 = Conv2D(64, filter_size, activation='relu', padding='same', kernel_initializer='he_normal')(conv1)\n",
        "    attn0 = spatial_attention_module(conv1)\n",
        "    bn1 = BatchNormalization(axis=-1)(attn0)\n",
        "    print('K.int_shape(bn1)',K.int_shape(bn1))\n",
        "    pool1 = MaxPooling2D(pool_size=(2, 2))(bn1)\n",
        "\n",
        "    conv2 = Conv2D(128, filter_size, activation='relu', padding='same', kernel_initializer='he_normal')(pool1)\n",
        "    conv2 = Conv2D(128, filter_size, activation='relu', padding='same', kernel_initializer='he_normal')(conv2)\n",
        "    attn1 = spatial_attention_module(conv2)\n",
        "    bn2 = BatchNormalization(axis=-1)(attn1)\n",
        "    pool2 = MaxPooling2D(pool_size=(2, 2))(bn2)\n",
        "\n",
        "    conv3 = Conv2D(256, filter_size, activation='relu', padding='same', kernel_initializer='he_normal')(pool2)\n",
        "    conv3 = Conv2D(256, filter_size, activation='relu', padding='same', kernel_initializer='he_normal')(conv3)\n",
        "    bn3 = BatchNormalization(axis=-1)(conv3)\n",
        "\n",
        "    up8 = Conv2D(128, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2,2), interpolation='nearest')(bn3))\n",
        "    merge8 = concatenate([up8, bn2], axis=3)\n",
        "    conv8 = Conv2D(128, filter_size, activation='relu', padding='same', kernel_initializer='he_normal')(merge8)\n",
        "    conv8 = Conv2D(128, filter_size, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
        "    conv8 = Conv2D(128, filter_size, activation='relu', padding='same', kernel_initializer='he_normal')(conv8)\n",
        "    bn8 = BatchNormalization(axis=-1)(conv8)\n",
        "\n",
        "    up9 = Conv2D(64, 2, activation='relu', padding='same', kernel_initializer='he_normal')(UpSampling2D(size=(2,2), interpolation='nearest')(bn8))\n",
        "    merge9 = concatenate([up9, bn1], axis=3)\n",
        "    conv9 = Conv2D(64, filter_size, activation='relu', padding='same', kernel_initializer='he_normal')(merge9)\n",
        "    conv9 = Conv2D(64, filter_size, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
        "    conv9 = Conv2D(64, filter_size, activation='relu', padding='same', kernel_initializer='he_normal')(conv9)\n",
        "    #UNet-----end-----------\n",
        "\n",
        "    output = Conv2D(n_output_classes, 1, activation='linear', name=\"unet_output\")(conv9)\n",
        "\n",
        "    model = Model(inputs = [input1, input2], outputs = [out, output])\n",
        "    #model.compile(optimizer=Adam(learning_rate=learning_rate), loss=loss, metrics = metrics)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def create_weight_map(image_shape, subregion, weight_inside, weight_outside):\n",
        "    \"\"\"\n",
        "    Create a weight map for an image, giving different weights to a specified subregion.\n",
        "\n",
        "    Parameters:\n",
        "    - image_shape: Tuple of the form (height, width), the shape of the image.\n",
        "    - subregion: Tuple of the form (start_row, start_col, end_row, end_col), specifying the subregion.\n",
        "    - weight_inside: The weight for pixels inside the subregion.\n",
        "    - weight_outside: The weight for pixels outside the subregion.\n",
        "\n",
        "    Returns:\n",
        "    - A 2D numpy array of shape `image_shape` with weights assigned to each pixel.\n",
        "    \"\"\"\n",
        "    weight_map = np.full(image_shape, weight_outside)\n",
        "    start_row, start_col, end_row, end_col = subregion\n",
        "    weight_map[start_row:end_row, start_col:end_col] = weight_inside\n",
        "    return weight_map\n"
      ],
      "metadata": {
        "id": "TiCRuQEtQ72N"
      },
      "id": "TiCRuQEtQ72N",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def weighted_loss(weight_map):\n",
        "    \"\"\"\n",
        "    Returns a loss function that calculates weighted loss, given a weight map.\n",
        "\n",
        "    Parameters:\n",
        "    - weight_map: A tensor of shape (height, width), representing the weight of each pixel.\n",
        "\n",
        "    Returns:\n",
        "    - A loss function that takes (y_true, y_pred) as input and returns the weighted loss.\n",
        "    \"\"\"\n",
        "    def loss(y_true, y_pred):\n",
        "        # Calculate the standard loss (e.g., binary crossentropy)\n",
        "        error = y_true - y_pred\n",
        "        squared_error = tf.square(error)\n",
        "        mean_squared_error = tf.reduce_mean(squared_error)\n",
        "        rmse = tf.sqrt(mean_squared_error)\n",
        "        return rmse\n",
        "        weighted_loss = tf.multiply(rmse, weighted_map) #new addition\n",
        "    return weighted_loss\n",
        "\n",
        "# Example usage\n",
        "# Assume `weight_map` is your predefined weight map, e.g., from create_weight_map function\n",
        "# model.compile(optimizer='adam', loss=weighted_loss(weight_map))\n"
      ],
      "metadata": {
        "id": "eZ0IaXmhSJWE"
      },
      "id": "eZ0IaXmhSJWE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d072a3f8",
      "metadata": {
        "id": "d072a3f8"
      },
      "outputs": [],
      "source": [
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scheduler(epoch, lr):\n",
        "  if epoch < 10:\n",
        "    return lr\n",
        "  else:\n",
        "    return lr * tf.math.exp(-0.1)#tf.keras.ops.exp(-0.1)"
      ],
      "metadata": {
        "id": "Bh_eE-1Cygty"
      },
      "id": "Bh_eE-1Cygty",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "89841a56",
      "metadata": {
        "id": "89841a56"
      },
      "outputs": [],
      "source": [
        "filter_size=3\n",
        "use_temp_scaling=False\n",
        "n_output_classes=1\n",
        "image_shape = (28,28)\n",
        "subregion = (10, 10, 15, 15)\n",
        "weight_inside = 8\n",
        "weight_outside = 1\n",
        "\n",
        "weight_map = create_weight_map(image_shape, subregion, weight_inside, weight_outside)\n",
        "\n",
        "loss = weighted_loss(weight_map)\n",
        "loss_weights = [0.25, 0.75]\n",
        "metrics = RootMeanSquaredError()\n",
        "model.compile(optimizer=Adam(), loss=loss, loss_weights = loss_weights, metrics = metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9fcb024",
      "metadata": {
        "id": "c9fcb024"
      },
      "outputs": [],
      "source": [
        "# define early stopping callback\n",
        "early_stopping = EarlyStopping(patience=5, restore_best_weights=True)\n",
        "callback = tf.keras.callbacks.LearningRateScheduler(scheduler)\n",
        "# fit model\n",
        "print(x_train.shape, y_train.shape)\n",
        "history = model.fit(x=[x_train2, x_train], y=[x_train2, y_train],epochs=60,batch_size=64,callbacks = [callback],validation_split=.2,verbose = 2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "368b2da7",
      "metadata": {
        "id": "368b2da7"
      },
      "outputs": [],
      "source": [
        "train = model.evaluate([x_train2,x_train], [x_train2,y_train])\n",
        "#print(\"Train MSE: {:.4f}\\nTrain Loss: {:.4f}\".format(train_mse, train_loss))\n",
        "\n",
        "test = model.evaluate([x_test2,x_test], [x_test2,y_test])\n",
        "#print(\"Test MSE: {:.4f}\\nTest Loss: {:.4f}\".format(test_mse, test_loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d52f34ad",
      "metadata": {
        "id": "d52f34ad"
      },
      "outputs": [],
      "source": [
        "_, y_pred = model.predict([x_test2,x_test])\n",
        "_, y_pred_cf = model.predict([x_test2,x_treated])\n",
        "print(y_pred.shape, y_pred_cf.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c0b49bd",
      "metadata": {
        "id": "1c0b49bd"
      },
      "outputs": [],
      "source": [
        "print(y_pred_cf.min(), y_pred_cf.max())\n",
        "print(y_pred.min(), y_pred.max())\n",
        "print(y_test.min(), y_test.max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3462bdfc",
      "metadata": {
        "id": "3462bdfc"
      },
      "outputs": [],
      "source": [
        "# invert scaling for forecasted values\n",
        "inv_y_pred = scaler_l.inverse_transform(y_pred.reshape(-1,1))\n",
        "inv_y_pred_cf = scaler_l.inverse_transform(y_pred_cf.reshape(-1,1))\n",
        "\n",
        "# invert scaling for actual values\n",
        "inv_y_test = scaler_l.inverse_transform(y_test.reshape(-1,1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77dca17c",
      "metadata": {
        "id": "77dca17c"
      },
      "outputs": [],
      "source": [
        "print(inv_y_pred_cf.min(), inv_y_pred_cf.max())\n",
        "print(inv_y_pred.min(), inv_y_pred.max())\n",
        "print(inv_y_test.min(), inv_y_test.max())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9a14d73",
      "metadata": {
        "id": "a9a14d73"
      },
      "outputs": [],
      "source": [
        "inv_y_pred = inv_y_pred.reshape(len(y_pred),28, 28)\n",
        "print(inv_y_pred.shape)\n",
        "inv_y_pred_cf = inv_y_pred_cf.reshape(len(y_pred_cf),28, 28)\n",
        "print(inv_y_pred_cf.shape)\n",
        "inv_y_test = inv_y_test.reshape(len(y_test),28, 28)\n",
        "print(inv_y_pred.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "730114a6",
      "metadata": {
        "id": "730114a6"
      },
      "outputs": [],
      "source": [
        "inv_y_test[1,1,1]- inv_y_pred[1,1,1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31962b4e",
      "metadata": {
        "id": "31962b4e"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
        "from math import sqrt\n",
        "\n",
        "rmse = sqrt(mean_squared_error(inv_y_test.flatten(), inv_y_pred.flatten()))\n",
        "print('Test RMSE: %.3f' % rmse)\n",
        "\n",
        "rmse1 = sqrt(mean_squared_error(cf_data.flatten(), inv_y_pred_cf.flatten()))\n",
        "print('Treated RMSE: %.3f' % rmse1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "704b10fa",
      "metadata": {
        "id": "704b10fa"
      },
      "outputs": [],
      "source": [
        "#DATE\n",
        "\n",
        "pred_att = inv_y_pred_cf[:4000,10:15, 10:15] - inv_y_pred[:4000,10:15, 10:15]\n",
        "mean_pred_att = np.mean(pred_att,axis=0)\n",
        "print(np.mean(mean_pred_att))\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.imshow(mean_pred_att, cmap='viridis')\n",
        "cbar = fig.colorbar(cax)\n",
        "ax.set_xlabel('x')\n",
        "ax.set_ylabel('y')\n",
        "ax.set_title('Mean Pred DATE')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27036461",
      "metadata": {
        "id": "27036461"
      },
      "outputs": [],
      "source": [
        "#DATE for 200:500 timesteps\n",
        "true_att = cf_data[:4000,10:15, 10:15] - inv_y_test[:4000,10:15, 10:15]\n",
        "mean_true_att = np.mean(true_att,axis=0)\n",
        "print(np.mean(mean_true_att))\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.imshow(mean_true_att, cmap='viridis')\n",
        "cbar = fig.colorbar(cax)\n",
        "ax.set_xlabel('x')\n",
        "ax.set_ylabel('y')\n",
        "ax.set_title('Mean True DATE')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9afd01d2",
      "metadata": {
        "id": "9afd01d2"
      },
      "outputs": [],
      "source": [
        "#ATE\n",
        "pred_ate = inv_y_pred_cf[:4000] - inv_y_pred[:4000]\n",
        "mean_pred_ate = np.mean(pred_ate,axis=0)\n",
        "print(np.mean(mean_pred_ate))\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.imshow(mean_pred_ate, cmap='viridis')\n",
        "cbar = fig.colorbar(cax)\n",
        "ax.set_xlabel('x')\n",
        "ax.set_ylabel('y')\n",
        "ax.set_title('Mean Pred ATE')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3b4b8606",
      "metadata": {
        "id": "3b4b8606"
      },
      "outputs": [],
      "source": [
        "#ATE\n",
        "true_ate = cf_data[:4000] - inv_y_test[:4000]\n",
        "mean_true_ate = np.mean(true_ate,axis=0)\n",
        "print(np.mean(mean_true_ate))\n",
        "print(mean_true_ate.shape)\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.imshow(mean_true_ate, cmap='viridis')\n",
        "cbar = fig.colorbar(cax)\n",
        "ax.set_xlabel('x')\n",
        "ax.set_ylabel('y')\n",
        "ax.set_title('Mean True ATE')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79ce9c54",
      "metadata": {
        "id": "79ce9c54"
      },
      "outputs": [],
      "source": [
        "#Mask for IATE\n",
        "mask = np.ones((28, 28))\n",
        "mask[10:15,10:15] = 0\n",
        "mask = mask.reshape(1,28, 28)\n",
        "mask_ts = np.tile(mask, (4998, 1, 1))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1780f1c1",
      "metadata": {
        "id": "1780f1c1"
      },
      "outputs": [],
      "source": [
        "#IATE for all timesteps\n",
        "true_iate = np.multiply(cf_data[:4000],mask_ts[:4000]) - np.multiply(inv_y_test[:4000],mask_ts[:4000])\n",
        "\n",
        "mean_true_iate = np.mean(true_iate,axis=0) #* 100\n",
        "print(np.mean(mean_true_iate))\n",
        "print(mean_true_iate.shape)\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.imshow(mean_true_iate, cmap='viridis')\n",
        "cbar = fig.colorbar(cax)\n",
        "ax.set_xlabel('x')\n",
        "ax.set_ylabel('y')\n",
        "ax.set_title('Mean True IATE')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d597c2f5",
      "metadata": {
        "id": "d597c2f5"
      },
      "outputs": [],
      "source": [
        "#IATE for all timesteps\n",
        "\n",
        "pred_iate = np.multiply(inv_y_pred_cf[:4000],mask_ts[:4000]) - np.multiply(inv_y_pred[:4000],mask_ts[:4000])\n",
        "\n",
        "mean_pred_iate = np.mean(pred_iate,axis=0)\n",
        "print(np.mean(mean_pred_iate))\n",
        "print(mean_pred_iate.shape)\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(111)\n",
        "cax = ax.imshow(mean_pred_iate, cmap='viridis')\n",
        "cbar = fig.colorbar(cax)\n",
        "ax.set_xlabel('x')\n",
        "ax.set_ylabel('y')\n",
        "ax.set_title('Mean Pred IATE')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c869cad5",
      "metadata": {
        "id": "c869cad5"
      },
      "outputs": [],
      "source": [
        "# Plotting the final state of the variables\n",
        "# Parameters\n",
        "Lx = 10.0      # Length of the domain in the x direction\n",
        "Ly = 10.0      # Length of the domain in the y direction\n",
        "Nx = 28        # Number of spatial points in the x direction\n",
        "Ny = 28        # Number of spatial points in the y direction\n",
        "\n",
        "# Spatial and temporal discretization\n",
        "x = np.linspace(0, Lx, Nx)\n",
        "y = np.linspace(0, Ly, Ny)\n",
        "X, Y = np.meshgrid(x, y)\n",
        "\n",
        "plt.figure(figsize=(18, 6))\n",
        "\n",
        "plt.subplot(1, 4, 1)\n",
        "plt.contourf(X, Y, inv_y_test[1500, :, :], cmap='viridis')\n",
        "plt.colorbar()\n",
        "plt.title('Pre-treatment Observation')\n",
        "\n",
        "plt.subplot(1, 4, 2)\n",
        "plt.contourf(X, Y, cf_data[1500, :, :], cmap='viridis')\n",
        "plt.colorbar()\n",
        "plt.title('Treated CF')\n",
        "\n",
        "plt.subplot(1, 4, 3)\n",
        "plt.contourf(X, Y, inv_y_pred[1500, :, :], cmap='viridis')\n",
        "plt.colorbar()\n",
        "plt.title('Pre-treatment Prediction')\n",
        "\n",
        "plt.subplot(1, 4, 4)\n",
        "plt.contourf(X, Y, inv_y_pred_cf[1500, :, :], cmap='viridis')\n",
        "plt.colorbar()\n",
        "plt.title('Predicted CF')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4aeea1b",
      "metadata": {
        "id": "f4aeea1b"
      },
      "outputs": [],
      "source": [
        "ts = inv_y_pred.shape[0]\n",
        "time_series1 = np.array([np.mean(inv_y_pred_cf[i,:,:]) for i in range(ts)])\n",
        "time_series2 = np.array([np.mean(cf_data[i,:,:]) for i in range(ts)])\n",
        "print(time_series2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71143ce8",
      "metadata": {
        "id": "71143ce8"
      },
      "outputs": [],
      "source": [
        "fig,ax = plt.subplots(figsize = [15,6], dpi = 400)\n",
        "ax.plot(range(ts),time_series1, label = \"Predicted CF\")\n",
        "ax.plot(range(ts),time_series2, label = \"True CF\")\n",
        "ax.legend()\n",
        "ax.set_xlabel(\"Time\")\n",
        "ax.set_ylabel(r\"Outcome(Y)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4509f550",
      "metadata": {
        "id": "4509f550"
      },
      "outputs": [],
      "source": [
        "ts = inv_y_pred.shape[0]\n",
        "time_series3 = np.array([np.mean(inv_y_pred_cf[i,10:15,10:15]) for i in range(ts)])\n",
        "time_series4 = np.array([np.mean(cf_data[i,10:15,10:15]) for i in range(ts)])\n",
        "print(time_series2.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8384c17",
      "metadata": {
        "id": "e8384c17"
      },
      "outputs": [],
      "source": [
        "ts = inv_y_pred.shape[0]\n",
        "time_series5 = np.array([np.mean(inv_y_test[i,:,:]) for i in range(ts)])\n",
        "time_series6 = np.array([np.mean(cf_data[i,:,:]) for i in range(ts)])\n",
        "print(time_series5.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "116360c5",
      "metadata": {
        "id": "116360c5"
      },
      "outputs": [],
      "source": [
        "fig,ax = plt.subplots(figsize = [15,6], dpi = 400)\n",
        "ax.plot(range(ts),time_series5, label = \"Factual Data\")\n",
        "ax.plot(range(ts),time_series6, label = \"Counterfactual Data\")\n",
        "ax.legend()\n",
        "ax.set_xlabel(\"Time\")\n",
        "ax.set_ylabel(r\"Outcome(Y)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20369ae1",
      "metadata": {
        "id": "20369ae1"
      },
      "outputs": [],
      "source": [
        "ts = inv_y_pred.shape[0]\n",
        "time_series7 = np.array([np.mean(inv_y_test[i,:,:]) for i in range(ts)])\n",
        "time_series8 = np.array([np.mean(inv_y_pred[i,:,:]) for i in range(ts)])\n",
        "print(time_series7.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "30ca79a1",
      "metadata": {
        "id": "30ca79a1"
      },
      "outputs": [],
      "source": [
        "fig,ax = plt.subplots(figsize = [15,6], dpi = 400)\n",
        "ax.plot(range(ts),time_series7, label = \"Actual Data\")\n",
        "ax.plot(range(ts),time_series8, label = \"Predicted Data\")\n",
        "ax.legend()\n",
        "ax.set_xlabel(\"Time\")\n",
        "ax.set_ylabel(r\"Outcome(Y)\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}